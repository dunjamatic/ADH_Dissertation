{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9599dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b387c2b",
   "metadata": {},
   "source": [
    "### Limit all predictor data to patients who have IHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36adb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "DIR = \"cleaned_files\"\n",
    "os.chdir(DIR)\n",
    "outcome =  pd.read_csv(\"outcomes.csv\")\n",
    "# get IHD patients IDs as the comparator (IHD pts in outcomes file)\n",
    "compare = outcome.e_patid\n",
    "\n",
    "DIR = \"merged_files\" # change to DIR where all the predictor files are stored \n",
    "os.chdir()\n",
    "age_gender = pd.read_csv(\"age_gender.csv\")\n",
    "crp = pd.read_csv(\"crp.csv\")\n",
    "diabetes = pd.read_csv(\"diabetes.csv\")\n",
    "height = pd.read_csv(\"height.csv\", sep = \"\\t\")\n",
    "weight = pd.read_csv(\"weight.csv\", sep = \"\\t\") \n",
    "alcohol = pd.read_csv(\"alcohol.csv\")\n",
    "\n",
    "outputdir = \"cleaned_files\"\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "\n",
    "# get the files you want to work with\n",
    "files = [age_gender, height, weight, crp, diabetes, alcohol] \n",
    "file_names = [\"age_gender\", \"height\", \"weight\", \"crp\", \"diabetes\", \"alcohol\"]\n",
    "\n",
    "# loop through each file and manipulate as desired\n",
    "for i in range(len(files)):\n",
    "    name = file_names[i] # get file name\n",
    "    in_data = files[i] # read file into dataframe\n",
    "    bools = in_data.e_patid.isin(compare) # get array of True/False for rows in in_data that have IHD \n",
    "    out_data = in_data[bools.values] # keep only rows with True\n",
    "    out_data.to_csv(outputdir + \"\\\\\" + name + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoking, CRP, Antiplatelets done in separate file (see bottom of this file for more detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c998a",
   "metadata": {},
   "source": [
    "### Now go through predictors and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the files that were just saved/created in the previous cell\n",
    "DIR = \"cleaned_files\"\n",
    "os.chdir(DIR) \n",
    "age_gender = pd.read_csv(\"age_gender.csv\") \n",
    "crp = pd.read_csv(\"crp.csv\")\n",
    "diabetes = pd.read_csv(\"diabetes.csv\") \n",
    "height = pd.read_csv(\"height.csv\")\n",
    "weight = pd.read_csv(\"weight.csv\")\n",
    "alcohol = pd.read_csv(\"alcohol.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f116133",
   "metadata": {},
   "source": [
    "#### age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AGE ####\n",
    "# isolate data frame for age\n",
    "age = age_gender.copy()\n",
    "age = age[[\"e_patid\", \"yob\", \"start\", \"end\"]]\n",
    "\n",
    "# calculate age at study entry (IHD diagnosis)\n",
    "# merge age and outcome data frames\n",
    "age_merged = pd.merge(outcome, age, on = 'e_patid', how = 'left')\n",
    "\n",
    "# drop irrelevant columns\n",
    "age_merged = age_merged[[\"e_patid\", \"obsdate\", \"yob\", \"start\", \"end\"]]\n",
    "\n",
    "# make outcome date and yob datetime objects\n",
    "age_merged[\"obsdate\"] = pd.to_datetime(age_merged[\"obsdate\"])\n",
    "age_merged[\"yob\"] = pd.to_datetime(age_merged[\"yob\"], format = '%Y') # make YOB day and month Jan 1\n",
    "\n",
    "# make new column with the age at baseline\n",
    "age_merged[\"baseline_age\"] = age_merged[\"obsdate\"].dt.year - age_merged[\"yob\"].dt.year\n",
    "\n",
    "# save the file\n",
    "DIR = \"cleaned_files\" # specify directory as desired\n",
    "os.chdir(DIR)\n",
    "age_merged.to_csv('age.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a95c8",
   "metadata": {},
   "source": [
    "#### gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GENDER ####\n",
    "\n",
    "# isolate this data frame to just gender because we will deal with age later\n",
    "gender = age_gender.copy()\n",
    "gender = gender [[\"e_patid\", \"gender\"]]\n",
    "\n",
    "# apply conditions to change the gender accordingly\n",
    "conditions = [\n",
    "    gender[\"gender\"] == \"M\",\n",
    "    gender[\"gender\"] == \"F\",\n",
    "    gender[\"gender\"] == \"I\"\n",
    "]\n",
    "\n",
    "values = [0, 1, np.nan]\n",
    "\n",
    "gender[\"gender_encoded\"] = np.select(conditions, values, default = np.nan)\n",
    "\n",
    "# merge gender with outcome data\n",
    "gender_merged = pd.merge(outcome, gender, on = 'e_patid', how = 'left')\n",
    "gender_merged = gender_merged[[\"e_patid\", \"gender\", \"gender_encoded\"]]\n",
    "\n",
    "# save the merged gender data frame\n",
    "DIR = 'cleaned_files' # change directory as needed\n",
    "os.chdir(DIR)\n",
    "gender_merged.to_csv('gender.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6da5d4",
   "metadata": {},
   "source": [
    "#### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6368de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DIABETES ####\n",
    "\n",
    "diabetes.rename(columns = {\"obsdate\": \"measuredate\"}, inplace = True)\n",
    "\n",
    "# create diabetes status column where all people with diabetes have a 1\n",
    "diabetes['diabetes_status'] = 1\n",
    "\n",
    "# merge outcome and diabetes so that now our 'diabetes status' has 1 for those with diabetes and 0 for those without\n",
    "merged_diabetes = pd.merge(outcome, diabetes, on = \"e_patid\", how = \"left\")\n",
    "merged_diabetes.diabetes_status = merged_diabetes.diabetes_status.replace(np.nan, 0)\n",
    "\n",
    "# drop unecessary columns\n",
    "merged_diabetes = merged_diabetes[[\"e_patid\", \"obsdate\", \"measuredate\", \"diabetes_status\"]]\n",
    "\n",
    "# only look at instances of diabetes recorded before the index date\n",
    "merged_diabetes['obsdate'] = pd.to_datetime(merged_diabetes['obsdate'])\n",
    "merged_diabetes['measuredate'] = pd.to_datetime(merged_diabetes['measuredate'], errors = 'coerce')\n",
    "\n",
    "# only mark 1 for those who had diabetes before study index date\n",
    "merged_diabetes['diabetes_status'] = ((merged_diabetes['diabetes_status'] == 1) & \n",
    "                                             (merged_diabetes['measuredate'] <= merged_diabetes['obsdate'])).astype(int)\n",
    "\n",
    "# Set value to 0 using boolean indexing\n",
    "merged_diabetes.loc[~((merged_diabetes['diabetes_status'] == 1) & \n",
    "                           (merged_diabetes['measuredate'] <= merged_diabetes['measuredate'])), \n",
    "                        'diabetes_status'] = 0\n",
    "\n",
    "DIR = 'cleaned_files'\n",
    "os.chdir(DIR)\n",
    "merged_diabetes.to_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00806025",
   "metadata": {},
   "source": [
    "#### weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WEIGHT ####\n",
    "\n",
    "# check what kind of invalid date formats there are --> looks like it is just nans\n",
    "not_datetime_weight = pd.to_datetime(weight[\"measuredate\"], errors = 'coerce', format = '%d%b%Y').isna()\n",
    "not_datetime_weight = weight.measuredate[not_datetime_weight].unique()\n",
    "\n",
    "weight[\"measuredate\"] = pd.to_datetime(weight[\"measuredate\"], errors = 'coerce', format = '%d%b%Y')\n",
    "weight = weight.sort_values([\"e_patid\", \"measuredate\"])\n",
    "\n",
    "# get units table from dataset (text file with measurement units of the predictor)\n",
    "units_id = pd.read_table(\"NumUnit.txt\")\n",
    "\n",
    "# then link weight and units_id based on the numunitid\n",
    "weight_units_merged = pd.merge(weight, units_id, on = 'numunitid', how = 'left')\n",
    "\n",
    "# next, add a column to weight with the numunitid description\n",
    "weight['unitdescription'] = weight_units_merged['Description']\n",
    "\n",
    "unit_counts_weight = weight.groupby('unitdescription').size().reset_index(name = 'counts')\n",
    "unit_counts_weight = unit_counts_weight.sort_values(by = 'counts', ascending = False)\n",
    "\n",
    "# \"drop\" values whose units cannot convert (will set them to NaN later)\n",
    "most_freq_weight_units = unit_counts_weight.drop(index = [1, 2, 28, 15, 13, 0, 5, 9, 6, 4, 7, 18, 3, 8, 10, 26, 27, 22, 25])\n",
    "# take note of the units being dropped (aka set to NaN)\n",
    "#1 (Unknown) \n",
    "#2 /kg(body wt) \n",
    "#28 mmol/L 0 % \n",
    "#15 Unk UoM \n",
    "#13 O/E - weight NOS \n",
    "#5 100 \n",
    "#7 160 \n",
    "#6 114 \n",
    "#4 0639 \n",
    "#8 255\n",
    "#9 7 \n",
    "#18 cm \n",
    "#3 /min \n",
    "#27 mmHg \n",
    "#10 8CAL\n",
    "#26 mm/Hg \n",
    "#25 metres \n",
    "#22 kg/m2 \n",
    "\n",
    "# specify the conversation rates for the units that I can convert\n",
    "conversion_rates_weight = {'kg': 1,\n",
    "                    'Kgs': 1,\n",
    "                    'kilograms': 1,\n",
    "                    'decimal stones': 6.35029,\n",
    "                    'Kilos': 1,\n",
    "                    'stone': 6.35029,\n",
    "                    'st': 6.35029,\n",
    "                    'Weight in Kg': 1,\n",
    "                    'kg.': 1,\n",
    "                    'WEIGHT IN KILOS': 5,\n",
    "                    'lb': 0.453592,\n",
    "                    'Stones': 6.35029} \n",
    "\n",
    "# create a boolean mask for the most common units\n",
    "common_units_weight = weight['unitdescription'].isin(most_freq_weight_units['unitdescription'])\n",
    "\n",
    "# set the values and units for the most common units\n",
    "weight.loc[common_units_weight, 'value'] *= weight.loc[common_units_weight, 'unitdescription'].map(conversion_rates_weight)\n",
    "weight.loc[common_units_weight, 'unitdescription'] = 'kg'\n",
    "\n",
    "# mark missing values for other units\n",
    "weight.loc[~common_units_weight, 'value'] = np.nan\n",
    "\n",
    "# create new column for weight (kg)\n",
    "weight[\"weight (kg)\"] = weight[\"value\"]\n",
    "\n",
    "# save file\n",
    "DIR = \"cleaned_files\"\n",
    "os.chdir(DIR)\n",
    "weight.to_csv('weight.csv', index = False)\n",
    "\n",
    "# NOW NEED TO DROP DUPLICATES --> new file (see Remove Duplicates folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2757f6",
   "metadata": {},
   "source": [
    "#### height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202284ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HEIGHT ####\n",
    "\n",
    "# get units table (text file with measurement units of the predictor)\n",
    "units_id = pd.read_table(\"NumUnit.txt\")\n",
    "\n",
    "# link height and units_id based on the numunitid\n",
    "height_units_merged = pd.merge(height, units_id, on = 'numunitid', how = 'left')\n",
    "\n",
    "# next, add a column to height data with the numunitid description\n",
    "height['unitdescription'] = height_units_merged['Description']\n",
    "\n",
    "# check what kind of invalid date formats there are --> looks like it is just nans\n",
    "not_datetime_height = pd.to_datetime(height[\"measuredate\"], errors = 'coerce', format = '%d%b%Y').isna()\n",
    "not_datetime_height = height.measuredate[not_datetime_height].unique()\n",
    "\n",
    "# change height dates into datetime object\n",
    "height[\"measuredate\"] = pd.to_datetime(height[\"measuredate\"], errors = 'coerce', format = '%d%b%Y')\n",
    "height = height.sort_values([\"e_patid\", \"measuredate\"])\n",
    "\n",
    "# look at the unique height units\n",
    "see_unique = height.unitdescription.unique()\n",
    "\n",
    "# look at most frequently used units \n",
    "unit_counts_height = height.groupby('unitdescription').size().reset_index(name = 'counts')\n",
    "unit_counts_height = unit_counts_height.sort_values(by = 'counts', ascending = False)\n",
    "\n",
    "# \"drop\" units that cannot be converted (set them to NaN later on)\n",
    "most_freq_height_units = unit_counts_height.drop(index = [0, 17, 7, 6, 1, 5, 12, 3, 2, 16, 11, 4])\n",
    "# note the units that are \"dropped\"\n",
    "#0 /min \n",
    "#17 mmHg \n",
    "#7 O/E-height 10-20% over average \n",
    "#6 O/E -height within 10% average \n",
    "#1 100 \n",
    "#5 O/E - loss of height \n",
    "#12 kg/m2 \n",
    "#3 160 \n",
    "#2 114 \n",
    "#16 mm/Hg \n",
    "#11 kg\n",
    "#4 Kgs \n",
    "\n",
    "# create conversion rate table for height\n",
    "conversion_rates_height = {'cm': 1,\n",
    "                    'm': 100,\n",
    "                    'cms': 1,\n",
    "                    'metres': 100,\n",
    "                    'mm': 0.1,\n",
    "                    'ft': 30.48} \n",
    "\n",
    "# create a boolean mask for the most common units\n",
    "common_units_height = height['unitdescription'].isin(most_freq_height_units['unitdescription'])\n",
    "\n",
    "# set the values and units for the most common units\n",
    "height.loc[common_units_height, 'value'] *= height.loc[common_units_height, 'unitdescription'].map(conversion_rates_height)\n",
    "height.loc[common_units_height, 'unitdescription'] = 'cm'\n",
    "\n",
    "# mark missing values for other units\n",
    "height.loc[~common_units_height, 'value'] = np.nan\n",
    "\n",
    "# create new column for weight (kg)\n",
    "height[\"height (cm)\"] = height[\"value\"]\n",
    "\n",
    "DIR = \"cleaned_files\"\n",
    "os.chdir(DIR)\n",
    "height.to_csv('height.csv', index = False)\n",
    "\n",
    "# NOW NEED TO DROP DUPLICATES --> new file (see Remove Duplicates folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97feefed",
   "metadata": {},
   "source": [
    "#### alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ALCOHOL ####\n",
    "\n",
    "# first check what the invalid dates are (e.g., nan, year is something ridiculous, etc.)\n",
    "not_datetime = pd.to_datetime(alcohol[\"measuredate\"], format=\"%d%b%Y\", errors='coerce').isna() # get invalid dates\n",
    "alcohol.measuredate[not_datetime].unique() # check what kinds of values are the invalid ones\n",
    "\n",
    "# turn the date column into a datetime object\n",
    "alcohol[\"measuredate\"] = pd.to_datetime(alcohol[\"measuredate\"], format = \"%d%b%Y\", errors = \"coerce\") #turn obsdate into datetime object\n",
    "alcohol = alcohol.sort_values([\"e_patid\", \"measuredate\"]) # sort values based on patient ID and obsdate\n",
    "\n",
    "# get units table (text file with measurement units of the predictor)\n",
    "units_id = pd.read_table(\"NumUnit.txt\")\n",
    "\n",
    "# then link alcohol and units_id based on the numunitid\n",
    "alcohol_units_merged = pd.merge(alcohol, units_id, on = 'numunitid', how = 'left')\n",
    "\n",
    "# next, add a column to alcohol with the numunitid description\n",
    "alcohol['unitdescription'] = alcohol_units_merged['Description']\n",
    "\n",
    "# convert value to be in units per week\n",
    "# classify each patient as \"0\" (0 units per week), \"1\" (between 0 and 10), \"2\" (greater than 10)\n",
    "\n",
    "# look at the different units \n",
    "unit_counts = alcohol.groupby('unitdescription').size().reset_index(name='counts')\n",
    "unit_counts = unit_counts.sort_values(by='counts', ascending = False)\n",
    "most_frequent_units = unit_counts\n",
    "# after manually looking through the data, I know I have to deal with units, Unit, Occasional, and 0 separately\n",
    "\n",
    "# for now, ignore the rows that I cannot convert like units, Unit, 0, Occasional\n",
    "most_frequent_units.drop(index = [1, 292, 286, 125, 285, 116, 235, 290, 281, 282, 289, 288, 287, 213, 10, 20, 48, 25, 253, 53, 31, 95, 33, 105, 100, 66, 4, 76, 343, 63, 72, 36, 128, 262, 38, 122, 88, 59, 117, 118, 110, 156, 132, 42, 147, 331, 218, 254, 93, 101, 60, 121, 123, 16, 57,  62, 61, 130, 247, 248, 249, 250, 251, 252, 258, 74, 260, 73, 291, 295, 293, 37, 32, 20, 28, 27, 23, 22, 15, 336, 337, 340, 5, 3, 39, 40, 242, 296, 298, 299, 55, 303, 304, 52, 51, 46, 44, 43, 41, 243, 241,166, 103, 102, 107, 108, 126, 140, 124, 114, 113, 112, 97, 240, 219, 220, 221, 22, 223, 225, 226, 83, 229, 216, 81, 237, 239, 215, 87, 91, 91, 90, 201, 203, 204, 205, 206, 209, 86, 0], inplace = True)\n",
    "most_common_units = most_frequent_units.unitdescription # descriptions for the most frequent units that I can convert\n",
    "most_common_units = most_common_units.to_frame()\n",
    "\n",
    "# change all alcohol values whose unitdescription is \"Occasional\" to 5\n",
    "# Occasional is in the top most common units and occasional implies not heavy drinker but not non-drinker\n",
    "alcohol.loc[alcohol['unitdescription'] == 'Occasional', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'Occasional', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == '4 times a year.', 'value'] == 1\n",
    "alcohol.loc[alcohol['unitdescription'] == '4 times a year.', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occasionally', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occasionally', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'U/occasionally', 'value'] == 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'U/occasionally', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'Rarely', 'value'] == 1\n",
    "alcohol.loc[alcohol['unitdescription'] == 'Rarely', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'every 3 weeks social'] == 1\n",
    "alcohol.loc[alcohol['unitdescription'] == 'every 3 weeks social', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'on special occas'] == 1\n",
    "alcohol.loc[alcohol['unitdescription'] == 'on special occas', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'on occasions'] == 1\n",
    "alcohol.loc[alcohol['unitdescription'] == 'on occasions', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occasionally only'] == 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occasionally only', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'on xmas day', 'value'] = 1\n",
    "alcohol.loc[alcohol['unitdescription'] == 'on xmas day', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'once a year', 'value'] = 1\n",
    "alcohol.loc[alcohol['unitdescription'] == 'once a year', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'once in a while', 'value'] = 1\n",
    "alcohol.loc[alcohol['unitdescription'] == 'once in a while', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'only on special oc', 'value'] = 1\n",
    "alcohol.loc[alcohol['unitdescription'] == 'only on special oc', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'less than monthly', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'less than monthly', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'less then monthly', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'less then monthly', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'not often', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'not often', 'unitdescription'] = 'units per week'\n",
    " \n",
    "alcohol.loc[alcohol['unitdescription'] == 'occa', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occa', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occasionallly', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occasionallly', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occasional drinker', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occasional drinker', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == ' rare occassions', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == ' rare occassions', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'socially not weekly', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'socially not weekly', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'sundays', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'sundays', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'U/ occasionally', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'U/ occasionally', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occ', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'occ', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'U/occasional', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'U/occasional', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == 'special occasions', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == 'special occasions', 'unitdescription'] = 'units per week'\n",
    "\n",
    "alcohol.loc[alcohol['unitdescription'] == '0cc', 'value'] = 5\n",
    "alcohol.loc[alcohol['unitdescription'] == '0cc', 'unitdescription'] = 'units per week'\n",
    "\n",
    "\n",
    "# create a conversion rates table to convert the most frequent units to \n",
    "# units/week\n",
    "# a lot of the most frequent units are a variation on units/week so no\n",
    "# point converting those (e.g., U/week, units/wk, etc.)\n",
    "\n",
    "conversion_rates = {'units/week' :1,  \n",
    "'U/week':1,\n",
    "'units':1, \n",
    "'units/wk':1, \n",
    "'units per week':1, \n",
    "'units}/wk':1,\n",
    "'/week':1,\n",
    "'units / week':1,\n",
    "' /wk':1,\n",
    "'Unit':1,\n",
    "'units/day': 7,\n",
    "'U/wk': 1,\n",
    "'Unt/Wk': 1,\n",
    "'upw': 1,\n",
    "'unit/wk': 1,\n",
    "'pw': 1, \n",
    "'U/month': 1/4,\n",
    "'/day':7,\n",
    "'units per wk': 1,\n",
    "'units/weeks': 1,\n",
    "'per week': 1,\n",
    "'U/monthly':1/4,\n",
    "'u/day':7,\n",
    "'month':1/4, \n",
    "'un/pw':1,\n",
    "'U/year':1/52, \n",
    "'monthly':1/4, \n",
    "'units/w':1, \n",
    "'Units/ week':1, \n",
    "'units /week':1, \n",
    "'u/pw':1, \n",
    "'week':1, \n",
    "'U/fortnight':1/2,\n",
    "'yearly':1/52, \n",
    "'day':7, \n",
    "'0U/week':1, \n",
    "'U/DAILY':7, \n",
    "'Alc Units/wk':1, \n",
    "'U/yearly':1/52, \n",
    "'units p.d.':7,\n",
    "'2 U/week':1, \n",
    "'1 U/week':1,\n",
    "'Alcohol Units Per Week':1, \n",
    "'fortnightly':1/2, \n",
    "'U/fortnightly':1/2,\n",
    "'U/months':1/4, \n",
    "'U/monthy':1/4, \n",
    "'0 U/week':1, \n",
    "'year':1/52, \n",
    "'14U/week':1, \n",
    "'x 2 monthly':1/8, \n",
    "'iu/wk':1, \n",
    "'per month':1/4, \n",
    "'U/6 months':1/24, \n",
    "'U/mth':1/4, \n",
    "'0/week':1, \n",
    "'units/weekly':1, \n",
    "'weeks':1,\n",
    "'8U/week':1, \n",
    "'u/weekly':1,\n",
    "'units pw':1, \n",
    "'1U/week':1, \n",
    "'10 U/week':1,\n",
    "'fortnight':1/2, \n",
    "'units p/wk':1, \n",
    "'umonth':1/4, \n",
    "'unit/week':1, \n",
    "'Units//week':1, \n",
    "'U/6 monthly':1/24, \n",
    "'U/2week':1/2, \n",
    "'weekly':1, \n",
    "'x 2 month':1/8, \n",
    "'U/6months':1/24, \n",
    "'amonth': 1/4, \n",
    "'U/night':7, \n",
    "'U/week6':1, \n",
    "'U/week0':1, \n",
    "'every 3 weeks':1/3, \n",
    "'pints beer/week': 2, \n",
    "'mth':1/4, \n",
    "'ou/week':1, \n",
    "'per day':7, \n",
    "'p/w':1, \n",
    "'U/peryear':1/52, \n",
    "'1/week':1,\n",
    "'5 U/week':1, \n",
    "'/month':1/4, \n",
    "'3 U/week':1, \n",
    "'2U':1, \n",
    "'28U/week':1, \n",
    "'21U/week':1, \n",
    "'3 units':1, \n",
    "'pints cider week':2,\n",
    "'3 month':1/12, \n",
    "'3 weeks':1/3,\n",
    "'4/week':1,\n",
    "'4 units':1, \n",
    "'4 U/week':1, \n",
    "'35U/week':1, \n",
    "'mounth':1/4, \n",
    "'3/week':1, \n",
    "'units last week':1, \n",
    "'14 U/week':1, \n",
    "'10U/week':1, \n",
    "'units/per week':1, \n",
    "'0 units':1, \n",
    "'0 u/wk':1, \n",
    "'0 /week':1, \n",
    "'-3 cans beer/day':16.8,\n",
    "'units in last week':1, \n",
    "'20U/week':1, \n",
    "'U/week':1, \n",
    "'u/3months':1/12, \n",
    "'20 U/week':1, \n",
    "'2 units':1, \n",
    "'1u':1, \n",
    "'unit/pw':1, \n",
    "'glasses wine/wkend':7.35, \n",
    "'6units':1, \n",
    "'8 U/week':1, \n",
    "'U/mthly':1/4, \n",
    "'7U/week':1, \n",
    "'U/per day 1':7,\n",
    "'U/per month':1/4, \n",
    "'U/w10eek':1, \n",
    "'U/week 1':1, \n",
    "'U/week 60':1, \n",
    "'U/week-5':1,\n",
    "'U/week.5':1, \n",
    "'6U/week':1, \n",
    "'U/week10':1, \n",
    "'U/week12':1, \n",
    "'U/week14':1, \n",
    "'U/week16':1, \n",
    "'U/week4':1, \n",
    "'U/week56':1, \n",
    "'U/moth':1/4, \n",
    "'U/week7':1, \n",
    "'U wkly':1, \n",
    "'U/ 3 months':1/12, \n",
    "'U/2WEEKS' : 1/2,\n",
    "'U/2monthly' : 1/8,\n",
    "'U/5 weeks' :1/5, \n",
    "'U/6monthy' : 1/24,\n",
    "'U/a month' :1/4,\n",
    "'9 U/week' :1,\n",
    "'U/annually' :1/52,\n",
    "'U/bi-monthly' :1/2,\n",
    "'U/every 2-3 months': 1/8, \n",
    "'U/forenight':1/2, \n",
    "'U/fornightly' :1/2,\n",
    "'9U/week' :1,\n",
    "'U/month. ' :1/4,\n",
    "'6 U/week' :1,\n",
    "'42U/week' :1,\n",
    "'42 U/week' :1,\n",
    "'40 U/week' :1,\n",
    "'glass brandy/night':9.8, \n",
    "'glass wine/day' :14.7,\n",
    "\"glass's wine/week\" :2.1,\n",
    "'glasses whiskey/Nt' : 9.8, \n",
    "'U 6 monthly' : 1/24, \n",
    "'cans larger/day' : 14, \n",
    "'5U/week':1, \n",
    "'U/yr':1/52, \n",
    "'U0/week' :1,\n",
    "'U16/week' :1,\n",
    "'Unit per week':1,\n",
    "'a year' :1/52,\n",
    "'a/day' :7,\n",
    "'bottles/week (wine) ' :10,\n",
    "'bottle spirits a day' : 280,\n",
    "'bottle wine/week' : 10,\n",
    "'bottles whiskey/day' : 280,\n",
    "'bottles wine a week': 10,\n",
    "'bottles wine/day' : 70\n",
    "}\n",
    "\n",
    "# create a boolean mask for the most common units\n",
    "common_units = alcohol['unitdescription'].isin(most_common_units['unitdescription'])\n",
    "\n",
    "# set the values and units for the most common units\n",
    "alcohol.loc[common_units, 'value'] *= alcohol.loc[common_units, 'unitdescription'].map(conversion_rates)\n",
    "alcohol.loc[common_units, 'unitdescription'] = 'units per week'\n",
    "\n",
    "# mark missing values for other units\n",
    "alcohol.loc[~common_units, 'value'] = np.nan\n",
    "\n",
    "# now create an alcohol status variable and stratify into:\n",
    "# 0 (<0 units per week), 1 (between 0 and 10 units per week), 2 (>10 units per week)\n",
    "\n",
    "conditions = [\n",
    "    alcohol['value'] == 0,\n",
    "    alcohol['value'].between(0, 10),\n",
    "    alcohol['value'] > 10\n",
    "]\n",
    "values = [0, 1, 2]\n",
    "\n",
    "# use numpy.select to apply the conditions to the entire DataFrame\n",
    "alcohol['alcohol_status'] = np.select(conditions, values, default = np.nan)\n",
    "\n",
    "# save cleaned alcohol data\n",
    "DIR = \"cleaned_files\"\n",
    "os.chdir(DIR)\n",
    "alcohol.to_csv('alcohol.csv', index = False)\n",
    "\n",
    "# NOW NEED TO DROP DUPLICATES --> new file (see Remove Duplicates folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27809c4d",
   "metadata": {},
   "source": [
    "#### CRP, Anitplatelets, Smoking are done in other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CRP #### --> fully dealt with in a new file (see Remove Duplicates folder)\n",
    "#### ANTIPLATELETS #### --> fully dealt with in a new file (see Remove Duplicates folder)\n",
    "#### SMOKING #### --> fully dealt with in a new file (see Remove Duplicates folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
