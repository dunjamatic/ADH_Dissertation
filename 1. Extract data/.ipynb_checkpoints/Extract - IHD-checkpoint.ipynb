{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad3424d",
   "metadata": {},
   "source": [
    "### Extract files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# If your data is split into multiple sections, then run this code for every section of data (changing file names as needed)\n",
    "DIR = \"original_files\" # directory where files are stored \n",
    "os.chdir(DIR)\n",
    "\n",
    "# make output folder if it does not already exist\n",
    "outputdir = \"merged_files\" # change directory, if needed\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "\n",
    "# get comparator (IHD medical codes, e.g. SNOMED codes)\n",
    "compare = pd.read_table(\"ihd-codes.txt\") \n",
    "\n",
    "# get the txt files you want to work with\n",
    "files = glob.glob('*.txt')\n",
    "\n",
    "# loop through each file and manipulate as desired\n",
    "for file in files:\n",
    "    print(file) # keep track of what loop you're on\n",
    "    name = os.path.basename(file).split('.')[0] # get file name\n",
    "    in_data = pd.read_table(file) # read file into dataframe    \n",
    "    bools = in_data.medcodeid.isin(compare.MedCodeId) # get array of True/False for rows in in_data that have IHD \n",
    "    out_data = in_data[bools.values] # keep only rows with True\n",
    "    out_data = out_data[[\"e_patid\", \"consid\", \"obsid\", \"obsdate\", \"parentobsid\", \"medcodeid\", \"probobsid\"]] # keep only relevant columns\n",
    "    out_data.to_csv(outputdir + \"\\\\\" + name + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c92dbf",
   "metadata": {},
   "source": [
    "### Merge all the individual files that were just extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"merged_files\" # change directory, if needed\n",
    "os.chdir(DIR)\n",
    "\n",
    "files = glob.glob('*.csv')\n",
    "\n",
    "df_merged = pd.DataFrame()\n",
    "for file in files:\n",
    "    print(file)\n",
    "    data = pd.read_csv(file)\n",
    "    df_merged = pd.concat([df_merged, data], axis = 0, ignore_index = True)\n",
    "\n",
    "# save copy before removing duplicates    \n",
    "df_merged.to_csv(\"ihd.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e0694",
   "metadata": {},
   "source": [
    "### Drop invalid dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which rows have an invalid date format\n",
    "badones = df_merged.loc[pd.to_datetime(df_merged['obsdate'], errors='coerce', format='%d/%m/%Y').isnull()]\n",
    "len_badones = len(badones)\n",
    "\n",
    "# get boolean array for which rows are nan (True) and which are something other than nan (False)\n",
    "bools_badones = badones[\"obsdate\"].isnull()\n",
    "\n",
    "# check how many are NaN and compare length of this to length of badones to know if any are something other than nan\n",
    "badones_nan = badones[bools_badones]\n",
    "len_diff = len_badones - len(badones_nan)\n",
    "\n",
    "# look at the bad ones that are something other than nan to decide how to deal with them \n",
    "badones[~bools_badones]\n",
    "\n",
    "# remove invalid dates because in my case they are all either NaN or completely invalid years, which we cannot impute \n",
    "# do this by concatenating the sub-df that has the \"badones\" to the original but drop duplicates \n",
    "df_merged = pd.concat([df_merged, badones]).drop_duplicates(keep = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5543c105",
   "metadata": {},
   "source": [
    "### For duplicate cases of IHD, keep earliest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacae2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the earliest instance of IHD diagnosis\n",
    "df_merged[\"obsdate\"] = pd.to_datetime(df_merged[\"obsdate\"], errors = \"coerce\") # turn obsdate into datetime object\n",
    "df_merged = df_merged.sort_values([\"e_patid\", \"obsdate\"]) # sort values based on patient ID and obsdate\n",
    "df_merged = df_merged.drop_duplicates(subset=['e_patid'], keep='first')\n",
    "df_merged.to_csv(\"ihd.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
